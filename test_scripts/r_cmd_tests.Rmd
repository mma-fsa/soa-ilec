---
title: "Untitled"
author: "Mike McPhee Anderson, FSA"
date: "2025-10-11"
output: html_document
---

```{r setup, include=FALSE}

library(DBI)
library(duckdb)
library(rpart)
library(tidyverse)

AGENT_LIB = "~/workspace/soa-ilec/soa-ilec/mcp/ilec_r_lib.R"
AGENT_WS_DIR = "~/workspace/soa-ilec/soa-ilec/data/workspaces/ul_model_data/workspace_8971f3ab-971f-4ad7-a984-72c4926ea63d"

```

## Setup work dir

```{r}

system(paste0("rm -rf ", AGENT_WS_DIR))
system(paste0("mkdir -p ", AGENT_WS_DIR))

```

## Setup database connection

```{r}

pq_path <- "/home/mike/workspace/soa-ilec/soa-ilec/data/ilec_perm_historical.parquet"

if (!exists("conn")) {
  conn <- DBI::dbConnect(duckdb::duckdb(read_only = T, dbdir = "~/workspace/soa-ilec/soa-ilec/data/ilec_data.duckdb"))
  DBI::dbExecute(conn, "set memory_limit='4GB'")
}

tbl_ilec_data <- tbl(
  conn, 
  sprintf("read_parquet('%s')", pq_path)) 

DBI::dbExecute(
  conn,
  sprintf("create or replace view ILEC_DATA as (%s)", dbplyr::sql_render(tbl_ilec_data))
)

```


```{r}
tbl_ilec_data %>% colnames()
```


## Test Agent Functionality

```{r}
source(AGENT_LIB)
setwd(AGENT_WS_DIR)

cmd_create_dataset(conn, "training_data", "select * from ILEC_DATA where observation_year <= 2016 and expdeathqx2015vbtwmi_bypol > 0")
cmd_create_dataset(conn, "testing_data", "select * from ILEC_DATA where observation_year > 2016 and expdeathqx2015vbtwmi_bypol > 0")

```

## test rpart

```{r}

setwd(AGENT_WS_DIR)

cmd_rpart <- function(conn, dataset, x_vars, offset_var, y_var, max_depth, cp) {

  # check if the dataset is a parquet file
  pq_filename <- sprintf("%s.parquet", dataset)
  if (file.exists(pq_filename)) {
    tbl_dataset <- tbl(conn, sprintf("read_parquet('%s.parquet')", dataset))  
  } else {
    # assume that it exists in duckdb (e.g. table / view)
    tbl_dataset <- tbl(conn, dataset)
  }
  
  rpart_data <- tbl_dataset %>%
    group_by(across(all_of(x_vars))) %>%
    summarise(
      offset = sum(!!sym(offset_var)),
      y = sum(!!sym(y_var)),
      .groups = "drop"
    ) %>%
    ungroup() %>%
    collect() %>%
    mutate(across(where(is.character), as.factor))
  
  rhs <- reformulate(x_vars)          
  rpart_formula <- update(rhs, cbind(offset, y) ~ .)  
  
  fit_rpart <- rpart(
    rpart_formula,
    rpart_data,
    method="poisson",
    control = rpart.control(
      cp = cp,
      maxdepth = max_depth
    )
  )
  
  prune_to_depth <- function(fit, maxdepth = 3) {
    fr <- fit$frame
    nn <- as.numeric(row.names(fr))
    d  <- rpart:::tree.depth(nn)  # node depth helper
    toss <- nn[d >= maxdepth & fr$var != "<leaf>"]  # cut splits at/after depth
    if (length(toss)) snip.rpart(fit, toss = toss) else fit
  }

  png("rpart_tree.png", width = 1400, height = 900, res = 150)  # adjust size/res as needed
  rpart.plot(
    prune_to_depth(fit_rpart),
    type = 2,          # split labels on branches, leaf nodes as boxes    
    faclen = 0,        # donâ€™t truncate factor levels
    cex = 0.8,         # global text size
    tweak = 0.90,      # box size tweak,
    digits = 3
  )
  dev.off()
  
  return(fit_rpart)
}


#source(AGENT_LIB)
setwd(AGENT_WS_DIR)

x_vars <- c("Gender", "Attained_Age", "Smoker_Status", "Issue_Year")

# test that it can run on a parquet
cmd_rpart(conn, "model_data_train", x_vars, "EXPDEATHQX2015VBTWMI_BYPOL", "NUMBER_OF_DEATHS", 3, 0.001)


```


```{r}

source(AGENT_LIB)
setwd(AGENT_WS_DIR)


x_vars <- c("gender", "attained_age", "smoker_status", "issue_year")

# test that it can run on a parquet
cmd_rpart(conn, "ILEC_DATA", x_vars, "expdeathqx2015vbtwmi_bypol", "number_of_deaths", 3, 0.001)

```

## test glmnet

```{r}

source(AGENT_LIB)
setwd(AGENT_WS_DIR)

x_vars <- c("gender", "attained_age", "smoker_status", "issue_year", "face_amount_band_int")

design_matrix_vars <- c(
  "gender:smoker_status",
  "gender*attained_age",
  "issue_year*attained_age",
  "face_amount_band_int"
)

cmd_glmnet(
  conn,
  "training_data",
  x_vars,
  design_matrix_vars,
  list(
    "gender" = "male",
    "smoker_status" = "NONSMOKER"
  ),
  list(
    "issue_year" = c(1980, 2022)
  ),
  "expdeathqx2015vbtwmi_bypol",
  "number_of_deaths",
  "1se"
)


```

```{r}

source(AGENT_LIB)
setwd(AGENT_WS_DIR)

cmd_run_inference(conn, "training_data", "scored_data")

```

```{r}

  sql_create_data <- sprintf(
    "copy(select * from read_parquet('%s')) to '%s' (FORMAT PARQUET, ROW_GROUP_SIZE 100000)",
    "/home/mike/workspace/soa-ilec/soa-ilec/mcp_agent_work/session_abcedfg/scored_data/*.parquet",
    "/home/mike/workspace/soa-ilec/soa-ilec/mcp_agent_work/session_abcedfg/scored_data.parquet"
  )
  DBI::dbExecute(conn, sql_create_data)

```

## Validate Inference

```{r}

tbl_test <- tbl(conn, "read_parquet('/home/mike/workspace/soa-ilec/soa-ilec/mcp_agent_work/session_264baa4a-a2d3-443f-ab05-6031229260ee/ul_train_data_model_preds.parquet')")

tbl_test %>% summarise(a = sum(Number_Of_Deaths), e = sum(MODEL_PRED))

```

## Create the perm extract

```{r}

perm_data <- read_rds("/var/data/ilec/ilec_perm_historical.rds")

arrow::write_parquet(perm_data, "/home/mike/workspace/soa-ilec/soa-ilec/data/ilec_perm_historical.parquet")


```


